#### Diminished repetition suppression reveals selective and systems-level face processing differences in ASD
Repeated exposure to a stimulus results in reduced neural response, or repetition suppression, in brain regions responsible for processing that stimulus. This rapid accommodation to repetition is thought to underlie learning, stimulus selectivity, and strengthening of perceptual expectations. Importantly, reduced sensitivity to repetition has been identified in several neurodevelopmental, learning, and psychiatric disorders including autism spectrum disorder (ASD) - a neurodevelopmental disorder characterized by challenges in social communication and repetitive behaviors and restricted interests. Reduced ability to exploit or learn from repetition in ASD is hypothesized to contribute to sensory hypersensitivities, and parallels several theoretical frameworks claiming that ASD individuals show difficulty using regularities in the environment to facilitate behavior. Using functional magnetic resonance imaging (fMRI) in autistic and neurotypical human adults (females and males), we assessed the status of repetition suppression across two modalities (vision, audition) and with four stimulus categories (faces, objects, printed words, and spoken words). ASD individuals showed domain-specific reductions in repetition suppression for face stimuli only, but not for objects, printed words, or spoken words. Reduced repetition suppression for faces was associated with greater challenges in social communication in ASD. We also found altered functional connectivity between atypically adapting cortical regions and higher-order face recognition regions and microstructural differences in related white matter tracts in ASD. These results suggest that fundamental neural mechanisms and system-wide circuits are selectively altered for face processing in ASD and enhance our understanding of how disruptions in the formation of stable face representations may relate to higher-order social communication processes.

#### Atypical cortical processing of bottom-up speech binding cues in children with autism spectrum disorders

Individuals with autism spectrum disorder (ASD) commonly display speech processing abnormalities. Binding of acoustic features of speech distributed across different frequencies into coherent speech objects is fundamental in speech perception. Here, we tested the hypothesis that the cortical processing of bottom-up acoustic cues for speech binding may be anomalous in ASD. We recorded magnetoencephalography while ASD children (ages 7–17) and typically developing peers heard sentences of sine-wave speech (SWS) and modulated SWS (MSS) where binding cues were restored through increased temporal coherence of the acoustic components and the introduction of harmonicity. The ASD group showed increased long-range feedforward functional connectivity from left auditory to parietal cortex with concurrent decreased local functional connectivity within the parietal region during MSS relative to SWS. As the parietal region has been implicated in auditory object binding, our findings support our hypothesis of atypical bottom-up speech binding in ASD. Furthermore, the long-range functional connectivity correlated with behaviorally measured auditory processing abnormalities, confirming the relevance of these atypical cortical signatures to the ASD phenotype. Lastly, the group difference in the local functional connectivity was driven by the youngest participants, suggesting that impaired speech binding in ASD might be ameliorated upon entering adolescence.

#### Multiple sources of variation affect speech processing efficiency
Phonetic variability across talkers imposes additional processing costs during speech perception, evident in performance decrements when listening to speech from multiple talkers. However, within-talker phonetic variation is a less well-understood source of variability in speech, and it is unknown how processing costs from within-talker variation compare to those from between-talker variation. Here, listeners performed a speeded word identification task in which three dimensions of variability were factorially manipulated: between-talker variability (single vs multiple talkers), within-talker variability (single vs multiple acoustically distinct recordings per word), and word-choice variability (two- vs six-word choices). All three sources of variability led to reduced speech processing efficiency. Between-talker variability affected both word-identification accuracy and response time, but within-talker variability affected only response time. Furthermore, between-talker variability, but not within-talker variability, had a greater impact when the target phonological contrasts were more similar. Together, these results suggest that natural between- and within-talker variability reflect two distinct magnitudes of common acoustic–phonetic variability: Both affect speech processing efficiency, but they appear to have qualitatively and quantitatively unique effects due to differences in their potential to obscure acoustic–phonemic correspondences across utterances.